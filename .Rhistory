library(readr)
library(forcats) #to work with factors
library(maps)
library(patchwork)#to put plots next to each other
library(tidytext)
library(stopwords)
library(ggrepel)
library(tidymodels)
install.packages('tidymodels')
library(tidyverse)
library(readr)
library(forcats) #to work with factors
library(maps)
library(patchwork)#to put plots next to each other
library(tidytext)
library(stopwords)
library(ggrepel)
library(tidymodels)
install.packages('maps')
install.packages('tidytext')
library(tidyverse)
library(readr)
library(forcats) #to work with factors
library(maps)
library(patchwork)#to put plots next to each other
library(tidytext)
library(stopwords)
library(ggrepel)
library(tidymodels)
RD_Toronto <- read_csv("H:/My Drive/UOIT/Teaching/2024/2024 Fall/2024 Fall MBAI 5100/Lecture 1, Sep 9/RawData/Toronto_RawData.csv")
RD_Vancouver <- read_csv("H:/My Drive/UOIT/Teaching/2024/2024 Fall/2024 Fall MBAI 5100/Lecture 1, Sep 9/RawData/Vancouver_RawData.csv")
RD_Toronto %>%
summary()
RD_Toronto %>%
slice(1:2) %>%
DT::datatable(class = 'cell-border stripe', options = list(pageLength = nrow(2)))
#RD_Toronto %>%
#  summarise_all(class) %>%
#  view()
library(knitr)
knitr::opts_chunk$set(fig.align = "center",
fig.width = 10,
fig.height = 10,
dev = "png",
cache = FALSE)
knitr::opts_chunk$set(echo = FALSE,
fig.align = "center",
#                      fig.width = 4,
#                      fig.height = 4,
dev = "png",
cache = FALSE)
1 + 2
44 - 32
5 * 11
2 ^ 3
2 ^ 1 ^ 3
98 / 9
98 %/% 9 #integer division
98 %% 9 #integer remainder
3 + 6 * 2
3 > 5
2 == 4 / 2
3 != 4
TRUE | FALSE
TRUE & FALSE
3+4
150 / (6 + 24)``` - 5
150 / (6 + 24) - 5
a <- c(1,2,3)
typeof(a)
a <- c(1,2,"3")
typeof(a)
a <- c(1,2,3)
typeof(a)
a <- c(1,2,3.2)
typeof(a)
a <- c(1.1, 2.2, 3.2)
typeof(a)
c()?
#
```
a <- list(1,3,"Hassan")
typeof(a)
5/6 == as.character(5/6)
5/6 == as.character(5/6)
5/6 == as.numeric(as.character(5/6))
5 == "5"
5 == as.numeric("5")
5/6 == as.numeric("5/6")
5 == as.numeric("5")
x <- 0:6
x
len(x)
length(x)
x[0]
x[1]
x[3]
x <- 1:6
x[3]
x[(3,4)]
x[c(3,4)]
x % 2 == 0
x %% 2 == 0
x // 2 == 0
x / 2 == 0
x / 2
x <- 1:10
x / 2
transactions_data
library(tidyverse)
library(dplyr)
library(ggplot2)
library(readr)
# Question 1 answer:----
# importing customer data:
customers_data <- read_csv("G:/My Drive/MBAI/BusinessAnalytics/Assignments/Assignment1/customers_data.csv")
# importing products data:
products_data <- read_csv("G:/My Drive/MBAI/BusinessAnalytics/Assignments/Assignment1/products_data.csv")
#importing transactions data:
transactions_data <- read_csv("G:/My Drive/MBAI/BusinessAnalytics/Assignments/Assignment1/transactions_data.csv")
transactions_data
head(transactions_data, 10)
is_tibble(customers_data)
glimpse(customers_data)
glimpse(products_data)
glimpse(transactions_data)
str(transactions_data)
transactions_data <- as.Date(transactions_data$Date, format = "%m/%d/%Y")
str(transactions_data)
transactions_data <- as.Date(transactions_data$Date, format = "%m/%d/%Y")
str(transactions_data)
transactions_data
transactions_data <- read_csv("G:/My Drive/MBAI/BusinessAnalytics/Assignments/Assignment1/transactions_data.csv")
head(transactions_data, 10)
transactions_data$Date <- as.Date(transactions_data$Date, format = "%m/%d/%Y")
str(transactions_data)
transactions_data
transactions_2023 <- transactions_data %>%
filter(YEAR == 2023)
transactions_2023 <- transactions_data %>%
filter(Year == 2023)
head(transactions_2023, 10)
glimpse(transactions_2023)
customer_summary <- transactions_data %>%
#Grouping by customer id as it is unique for each customer:
group_by(Customer_ID) %>%
#summarizing the previous output to get the count and the total amount spent:
summarise(
Total_Transactions = n(),
Total_Amount_Spent = sum(Total_Amount)
)
head(customer_summary, 10)
joined_customers_data <- left_join(customers_data, customer_summary, by="Customer_ID")
customer_summary <- transactions_data %>%
#Grouping by customer id as it is unique for each customer:
group_by(Customer_ID) %>%
#summarizing the previous output to get the count and the total amount spent:
summarise(
Number_of_Transactions = n(),
Total_Amount_Spent = sum(Total_Amount)
)
head(customer_summary, 10)
premium_customers <- customers_data %>%
inner_join(customer_summary, by=Customer_ID) %>%
filter(Total_Amount_Spent >= 10000) %>%
rename(Total_Transaction = Total_Amount_Spent) %>%
select(-Number_of_Transactions)
premium_customers <- customers_data %>%
inner_join(customer_summary, by="Customer_ID") %>%
filter(Total_Amount_Spent >= 10000) %>%
rename(Total_Transaction = Total_Amount_Spent) %>%
select(-Number_of_Transactions)
head(premium_customers, 10)
premium_customers
glimpse(premium_customers)
products_data
transactions_data
products_transaction <- transactions_data %>%
inner_join(products_data, by="Product_ID") %>%
group_by(Category) %>%
summarise(Numeber_of_Transactions= n())
ggplot(products_transaction,
#setting up the aesthetics:
aes(x= Category, y=Number_of_Transactions)) +
# setting up the bar plot
geom_bar(stat = "identity", fill = "darkorange") +
#setting up the titles and labels:
labs(title = "Number of Transactions by Product category",
x = "Products Category",
y = "Number of Transactions") +
theme_minimal()
products_transaction <- transactions_data %>%
# joinning the products data:
inner_join(products_data, by="Product_ID") %>%
# grouping by Category:
group_by(Category) %>%
# calculating the total number od transactions by category:
summarise(Numeber_of_Transactions= n())
products_transaction
ggplot(products_transaction,
#setting up the aesthetics:
aes(x= Category, y=Number_of_Transactions)) +
# setting up the bar plot
geom_bar(stat = "identity", fill = "#FF8C00") +
#setting up the titles and labels:
labs(title = "Number of Transactions by Product category",
x = "Products Category",
y = "Number of Transactions") +
theme_minimal()
products_transaction <- transactions_data %>%
# joinning the products data:
inner_join(products_data, by="Product_ID") %>%
# grouping by Category:
group_by(Category) %>%
# calculating the total number od transactions by category:
summarise(Number_of_Transactions= n())
products_transaction
ggplot(products_transaction,
#setting up the aesthetics:
aes(x= Category, y=Number_of_Transactions)) +
# setting up the bar plot
geom_bar(stat = "identity", fill = "#FF8C00") +
#setting up the titles and labels:
labs(title = "Number of Transactions by Product category",
x = "Products Category",
y = "Number of Transactions") +
theme_minimal()
Discount = 0.10
transactions_data <- transactions_data %>%
mutate(Discounted_Amount = ifelse(Total_Amount > 100, Total_Amount * (1 - Discount), Total_Amount))
head(transactions_data)
library(xgboost)
install.packages("xgboost")
library(xgboost)
train_label <- train_data$Average_Price
library(tidyverse)
library(dplyr)
library(tidygeocoder)
library(shiny)
################### 1. Importing Data ####################
recession_indicator <- read.csv("./Data/CanadaRecessionIndicator.csv")
setwd("G:/My Drive/MBAI/BusinessAnalytics/FinalProject/HousingMarket-BA")
library(tidyverse)
library(dplyr)
library(tidygeocoder)
library(shiny)
################### 1. Importing Data ####################
recession_indicator <- read.csv("./Data/CanadaRecessionIndicator.csv")
rates <-read.csv("./Data/clean_rates.csv")
home_prices <- read.csv("./Data/GTA_HomePrice_History.csv")
primary_keys <- read.csv("./prim_key.csv")
###################### Exploratory Data Analysis and Data Processing ############################
# Missing Values
# Duplicates
# Number of rows and columns
data_q_report <- function(data) {
if (!is.data.frame(data)) {
stop("Input must be a data frame.")
}
# 1. View Columns
cat("Column Names:\n")
print(colnames(data))
# 2. Check for Nulls
null_counts <- sapply(data, function(x) sum(is.na(x)))
cat("\nNull counts per column:\n")
print(null_counts)
# Identify columns with any null values
columns_with_nulls <- colnames(data)[apply(data, 2, anyNA)]
cat("\nColumns with null values:\n")
print(columns_with_nulls)
# 3. Check for Duplicates
duplicates <- data[duplicated(data), ]
cat("\nDuplicate rows:\n")
print(duplicates)
# 4. Summary Report
cat("\nSummary Report:\n")
cat("Total Columns:", ncol(data), "\n")
cat("Total Rows:", nrow(data), "\n")
cat("Columns with Nulls:", paste(columns_with_nulls, collapse = ", "), "\n")
cat("Number of Duplicate Rows:", nrow(duplicates), "\n")
}
data_q_report(recession_indicator)
data_list <- list(recession_data=recession_indicator, homePrices = home_prices, primaryKeys = primary_keys, interestR=rates)
for (data in names(data_list)) {
cat("\nData Quality report for", data, ":\n")
data_q_report(data_list[[data]])
}
head(home_prices)
prices_recession <- inner_join(home_prices, recession_indicator, by = "Year_Quarter_Key")
merged_data <- inner_join(prices_recession, rates, by = "Year_Quarter_Key")
head(merged_data)
data_q_report(merged_data)
# Selecting the specific columns:
library(tmaptools)  # For OpenStreetMap geocoding
selected_data <- merged_data %>%
select(-1,-4,-12,-13,-14,-15,-16,-17,-18)
# safe_geocode <- function(area_name) {
#   tryCatch({
#     # Geocode using OpenStreetMap
#     geocode_result <- geocode_OSM(area_name)
#     return(geocode_result)
#   }, error = function(e) {
#     # In case of an error, return NAs
#     return(data.frame(lat = NA, lon = NA))
#   })
# }
#
# # Apply geocoding to each row with error handling
# final_data <- selected_data %>%
#   rowwise() %>%
#   mutate(
#     geocode_result = list(safe_geocode(Area)),
#     latitude = geocode_result[[1]]$lat,
#     longitude = geocode_result[[1]]$lon
#   ) %>%
#   ungroup() %>%
#   select(-geocode_result)
final_data <- selected_data
head(final_data)
######### 2. Exploratory Data Analysis ###################
library(psych)
# summary
# Univaritae analysis: Distribution of individual features
# Bivariate Analysis: Relationships between variables
# Geospatial Analysis : ggmap & sf
# Trends over time.
print(colnames(final_data))
describe(final_data)
## qualitative features:
#
# Data preprocessing
municipalities <- table(final_data$Municipality)
areas <- table(final_data$Area)
head(final_data)
# Grouping by year and area, and calculating the average price
avgPrice_area <- final_data %>%
group_by(X_Year.x, Municipality) %>%
summarize(avg_price = mean(Average_Price, na.rm = TRUE), .groups = "drop")  # Fixing the column name here
head(avgPrice_area)
# Bar chart of average price by area
ggplot(avgPrice_area, aes(x = Municipality, y = avg_price)) +
geom_bar(stat = "identity", color = "purple") +
theme_minimal() +
theme(
axis.text.x = element_text(angle = 90, hjust = 1)  # Rotate x-axis labels by 45 degrees
)
############## 3. Feature Engineering ######################
# Categorical Conversion of qualitative factors: factor()
# Normalizing or Scaling the features
final_prepped
final_prepped %>% select(Sales, Dollar_Volume, New_Listings, CANRECDM, avg_five_year_rates) %>%
summary()
head(final_data)
value_counts <- table(final_data$Municipality)
value_counts
final_numeric <- select(final_data, where(is.numeric))
head(final_numeric)
dummy_vars <- dummyVars(~ Area + Municipality, data = final_data)
library(caret)
library(leaflet)
head(final_data)
value_counts <- table(final_data$Municipality)
value_counts
final_numeric <- select(final_data, where(is.numeric))
head(final_numeric)
dummy_vars <- dummyVars(~ Area + Municipality, data = final_data)
encoded_categorical <- as.data.frame(predict(dummy_vars, newdata = final_data))
final_prepped <- cbind(final_numeric, encoded_categorical)
head(final_prepped)
final_prepped %>% select(Sales, Dollar_Volume, New_Listings, CANRECDM, avg_five_year_rates) %>%
summary()
cor(final_prepped %>% select(Sales, Dollar_Volume, New_Listings, CANRECDM, avg_five_year_rates, AreaDurham))
library(corrplot)
cor_matrix <- cor(final_prepped %>% select(Sales, Dollar_Volume, New_Listings, CANRECDM, avg_five_year_rates, AreaDurham))
corrplot(cor_matrix, method = "square")
#for year 2001
ggplot(final_data %>% filter(X_Year.x == 2001 ), aes(x = Area, y = New_Listings)) +
geom_boxplot(fill = "lightblue", color = "black") +  # Box plot with specified colors
theme_minimal() +  # Minimal theme for a cleaner look
labs(
title = "Box Plot of New Listings by Area",
x = "Area",
y = "New Listings"
) +
theme(
plot.title = element_text(hjust = 0.5, size = 16),  # Title alignment and size
axis.title = element_text(size = 12),  # Axis title size
axis.text.x = element_text(angle = 45, hjust = 1)  # Rotate x-axis labels for readability
)
#for year 2022
ggplot(final_data %>% filter(X_Year.x == 2021 & New_Listings > 0), aes(x = Area, y = New_Listings)) +
geom_boxplot(fill = "lightblue", color = "black") +  # Box plot with specified colors
theme_minimal() +  # Minimal theme for a cleaner look
labs(
title = "Box Plot of New Listings by Area",
x = "Area",
y = "New Listings"
) +
theme(
plot.title = element_text(hjust = 0.5, size = 16),  # Title alignment and size
axis.title = element_text(size = 12),  # Axis title size
axis.text.x = element_text(angle = 45, hjust = 1)  # Rotate x-axis labels for readability
)
yearly_listings <- final_data %>%
group_by(X_Year.x) %>%
summarise(total_listings = sum(New_Listings, na.rm = TRUE))
# Plotting the total listings by year as a bar chart
ggplot(yearly_listings, aes(x = as.factor(X_Year.x), y = total_listings)) +
geom_bar(stat = "identity", fill = "lightblue", color = "black") +  # Bar chart with specified colors
theme_minimal() +  # Minimal theme for a cleaner look
labs(
title = "Total New Listings by Year",
x = "Year",
y = "Total New Listings"
) +
theme(
plot.title = element_text(hjust = 0.5, size = 16),  # Title alignment and size
axis.title = element_text(size = 12),  # Axis title size
axis.text.x = element_text(angle = 45, hjust = 1)  # Rotate x-axis labels for readability
)
library(ggplot2)
#install.packages('corrplot')
library(corrplot)
library(stats)
summary_stats <-  selected_data %>%
select(Sales, Dollar_Volume, Average_Price, New_Listings) %>%
summary()
print(summary_stats)
ggplot(merged_data, aes(x = X_Year.x, y = Average_Price)) +
geom_col() +
labs(title = "Average Price over Time", x = "Year Quarter", y = "Average Price") +
theme_minimal()
################# 5. Regression Modelling ##########
## Data Peocessing:
colnames(final_prepped)
colnames(final_prepped) <- make.names(colnames(final_prepped))
independent_columns <- colnames(final_prepped)[!colnames(final_prepped) %in% c("Average_Price")]
formula <- as.formula(paste("Average_Price ~", paste(independent_columns, collapse = " + ")))
lm_model <- lm(formula, data = final_prepped)
# Summary of the model
summary(lm_model)
# splitting data
# model selection
# triaining or fitting the model
# evaluating the model
# model improvements
# Results Interpretation
colnames(final_prepped)
# Group by Municipality and calculate the mean of Average_Price
model <- lm(Average_Price ~ Sales + Dollar_Volume + New_Listings + CANRECDM +
X_Indicator + avg_five_year_rates + AreaDurham, data = final_prepped)
# Display the summary of the model
summary(model)
# Check model diagnostics
par(mfrow = c(2, 2))
plot(model)
anova_model <- aov(Average_Price ~ AreaDurham, data = final_prepped)
summary(anova_model)
# Scatter plot to check relationship between Average_Price and another variable (e.g., Dollar_Volume)
ggplot(final_prepped, aes(x = Dollar_Volume, y = Average_Price)) +
geom_point() +
geom_smooth(method = "lm", col = "blue") +
labs(title = "Relationship between Dollar Volume and Average Price", x = "Dollar Volume", y = "Average Price")
# Boxplot for categorical variables (e.g., AreaDurham)
ggplot(final_prepped, aes(x = as.factor(AreaDurham), y = Average_Price)) +
geom_boxplot() +
labs(title = "Average Price by AreaDurham", x = "AreaDurham", y = "Average Price")
####################################3 Machine Learning #################################################
# splitting the data:
set.seed(123)
# Split the data into 70% for training and 30% for testing
train_index <- sample(1:nrow(final_prepped), 0.7 * nrow(final_prepped))
train_data <- final_prepped[train_index, ]
test_data <- final_prepped[-train_index, ]
#Linear Regression:
# Train a linear regression model
lm_model <- lm(Average_Price ~ ., data = train_data)
# View the summary of the model
summary(lm_model)
# Make predictions on the test set
lm_predictions <- predict(lm_model, newdata = test_data)
# Calculate RMSE
lm_rmse <- sqrt(mean((lm_predictions - test_data$Average_Price)^2))
cat("Linear Regression RMSE:", lm_rmse, "\n")
# library(randomForest)
#
# #Randdom Forest:
# rf_model <- randomForest(Average_Price ~., data = train_data)
#
# # View the summary of the model
# print(rf_model)
#
# # Make predictions on the test set
# rf_predictions <- predict(rf_model, newdata = test_data)
#
# # Calculate RMSE
# rf_rmse <- sqrt(mean((rf_predictions - test_data$Average_Price)^2))
# cat("Random Forest RMSE:", rf_rmse, "\n")
library(xgboost)
train_label <- train_data$Average_Price
test_label <- test_data$Average_Price
xg_model <- xgboost(data = train_dara, label = train_label,
objective = "reg:squarederror", nrounds = 100)
xg_model <- xgboost(data = train_data, label = train_label,
objective = "reg:squarederror", nrounds = 100)
train_matrix <- as.matrix(train_data[, setdiff(names(train_data), "Average_Price")])
test_matrix <- as.matrix(test_data[, setdiff(names(test_data), "Average_Price")])
xg_model <- xgboost(data = train_matrix, label = train_label,
objective = "reg:squarederror", nrounds = 100)
xg_predictions <- predict(xg_model, newdata = test_matrix)
xg_rmse <- sqrt(mean((xg_predictions - test_label)^2))
cat("XGBoost RMSE:", xg_rmse, "\n")
